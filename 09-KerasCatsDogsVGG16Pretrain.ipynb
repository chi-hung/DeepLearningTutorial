{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本筆記讓大家有概念，如何使用pretrained model來做圖像分類。\n",
    "\n",
    "以下程式碼大多參考自Keras作者François Chollet的 [**教學**](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) 以及他的書：[deep-learning-with-python](https://www.manning.com/books/deep-learning-with-python)。於新版Keras(```v2.1.2```)下，他的範例無法執行，故我有稍做修正。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 筆記內容：\n",
    "\n",
    "* [略為了解一下資料集](#01)\n",
    "* [利用pretrained model建置模型](#02)\n",
    "* [模型微調](#03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =====================================================================\n",
    "# # 由於課堂上可能有多人共用同一顆GPU，以下限定使用者只能用計算卡上面一半的記憶體。\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5 # 使用一半記憶體\n",
    "# set_session(tf.Session(config=config))\n",
    "# # ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import load_model\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='01'>略為了解一下資料集</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_dogs,=!ls ../datasets/cats_and_dogs/train/dogs | wc -l\n",
    "num_train_cats,=!ls ../datasets/cats_and_dogs/train/cats | wc -l\n",
    "num_test_dogs,=!ls ../datasets/cats_and_dogs/validation/dogs | wc -l\n",
    "num_test_cats,=!ls ../datasets/cats_and_dogs/validation/cats | wc -l\n",
    "\n",
    "print(\"狗的train/test張數=\",num_train_dogs,num_test_dogs)\n",
    "print(\"貓的train/test張數=\",num_train_cats,num_test_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看一張貓的照片:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機載入一張貓的圖片\n",
    "fig_idx=np.random.choice(1000)\n",
    "img=cv2.imread(\"../datasets/cats_and_dogs/train/cats/cat.%s.jpg\"%fig_idx)\n",
    "# 繪圖\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看一張狗的照片:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機載入一張狗的圖片\n",
    "fig_idx=np.random.choice(1000)\n",
    "img=cv2.imread(\"../datasets/cats_and_dogs/train/dogs/dog.%s.jpg\"%fig_idx)\n",
    "# 繪圖\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E7%AD%86%E8%A8%98%E5%85%A7%E5%AE%B9%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -hl ../pretrain_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 紀錄兩個放置模型參數的檔案路徑\n",
    "path_with_top=\"../pretrain_models/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "path_without_top=\"../pretrain_models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #看一下模型架構(without top)\n",
    "# model = applications.VGG16(weights=path_without_top, include_top=False)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #看一下模型架構(with top)\n",
    "# model = applications.VGG16(weights=path_with_top, include_top=True)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='02'>利用pretrained model建置模型</a>\n",
    "\n",
    "我們即將建立的模型可分為兩個部分：pretrained convolutional part以及final classification part。\n",
    "\n",
    "其中，pretrained convolutional part是由已經訓練好的VGG16模型擷取而出。這個已訓練好的VGG16模型是由ImageNet資料集訓練而來。\n",
    "\n",
    "而final classification part並無做過任何訓練，也就是說，它裡面的參數是被隨機初始化的。\n",
    "\n",
    "我們將pretrained convolutional part結合後面的final classification part之後，丟入貓狗資料集，來訓練final classification part內的權重參數。\n",
    "\n",
    "於訓練過程中，我們不會訓練pretrained convolutional part，這是因為它已經內含一些\"規則\"，能夠將原本的圖片整理成適合拿來分類貓狗的\"高階特徵\"。有了這些適合分類貓狗的高階特徵後，final classification part就可以比較容易的利用這些高階特徵去做貓狗分類了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../datasets/cats_and_dogs/train/'           # 訓練資料位置\n",
    "validation_data_dir = '../datasets/cats_and_dogs/validation/' # 驗證資料位置\n",
    "\n",
    "\n",
    "# 建立VGG 16網路(前面conv block的部分)\n",
    "conv_base = applications.VGG16(weights=path_without_top,\n",
    "                               include_top=False,\n",
    "                               input_shape=(150,150,3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../datasets/cats_and_dogs/train/'           # 訓練資料位置\n",
    "validation_data_dir = '../datasets/cats_and_dogs/validation/' # 驗證資料位置\n",
    "\n",
    "\n",
    "# 建立VGG 16網路(前面conv block的部分)\n",
    "conv_base = applications.VGG16(weights=path_without_top,\n",
    "                               include_top=False,\n",
    "                               input_shape=(150,150,3))\n",
    "# 於conv block之後附加一個用於分類的block\n",
    "x = Flatten()(conv_base.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "# 將conv block和末端用於分類的block結合成一個模型\n",
    "model = Model(conv_base.input, preds)\n",
    "# 告知模型，不需要訓練前面的conv layers (我們只要訓練後面用於分類的block)\n",
    "conv_base.trainable = False\n",
    "# 編譯模型，告知模型訓練方式\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "# ============================================================\n",
    "# 產生train/test generator。generator會從資料夾內撈出一個批次的圖，\n",
    "# 並將該批次的圖像做augmentation。\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,                                       \n",
    "        target_size=(150, 150),                          \n",
    "        batch_size=20,\n",
    "        class_mode='binary')                             \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "# ============================================================\n",
    "\n",
    "# 訓練模型。圖片將以generator的方式餵入模型。\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "#畫出訓練過程\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E7%AD%86%E8%A8%98%E5%85%A7%E5%AE%B9%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "練習：試著自建一個簡單的CNN模型(不超過5個Convolutional layer)，看你能達成多高的模型準確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 練習於此\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "#                         input_shape=(150, 150, 3)))\n",
    "# model.add(...)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E7%AD%86%E8%A8%98%E5%85%A7%E5%AE%B9%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='03'>模型微調</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先看一下模型架構："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先前有提到，我們不建議將整個convolutional part拿去做訓練。事實上，這是因為該part的最前面幾個layers內含一些常見規則，可以把原圖片轉換成一些基本特徵。又，因為那些基本特徵是相當適用於各種影像分類場合的，所以我們不需要將那些layers裡面的權重參數再去做重新訓練。\n",
    "\n",
    "不過，訓練部分convolutional part則是合理的。除了訓練classification part之外，我們還可以選擇針對convolutional part的最後幾個layers來做再訓練。這是因為，那些後面的layers可能內含一些規則，可以把原圖片轉換成較複雜的高階特徵。然而，事實上，這些後面的layers所轉換出來的高階特徵是比較針對於ImageNet圖片集的分類。換句話說，那些高階特徵是被整理出來，專門用來分類1000類各種形形色色的物體的(ImageNet內含1000類圖片)。因此，最後幾個layer所內含的規則，有可能會過於複雜，有可能會不完全適用於較容易的貓狗圖片分類。\n",
    "\n",
    "因此，以下我們建模的時候，除了訓練後面的classification part之外，我們還多訓練了convolutional part的最後一個block (block 5)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將conv block5調整為可訓練\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編譯模型，告知模型訓練方式\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "# 訓練模型\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "# 畫出訓練過程\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E7%AD%86%E8%A8%98%E5%85%A7%E5%AE%B9%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
